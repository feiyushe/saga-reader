{
  "data": {
    "main_workflow": {
      "name": "文章智能处理与阅读流程",
      "description": "用户选择一篇文章后，系统从数据库或网络抓取原始内容，并通过LLM代理依次执行净化（Purge）、优化（Optimize）和融合（Melt）三个阶段的智能处理，最终将结构化、高质量的内容呈现给用户。该流程是系统的核心价值所在，实现了从原始网页到可读性强的知识内容的转化。",
      "flowchart_mermaid": "graph TD\n    A[用户点击文章] --> B{文章内容是否存在}\n    B -->|否| C[启动内容抓取]\n    C --> D[RSS/搜索/直接URL抓取]\n    D --> E[提取正文文本]\n    B -->|是| F[加载已存档内容]\n    E --> G[LLM净化: 去除噪音]\n    F --> G\n    G --> H[LLM优化: 结构化摘要]\n    H --> I[LLM融合: 深度洞察生成]\n    I --> J[更新数据库]\n    J --> K[前端展示优化后内容]\n    K --> L[用户获得智能阅读体验]"
    },
    "other_important_workflows": [
      {
        "name": "应用启动初始化流程",
        "description": "应用程序启动时，首先加载全局配置和日志系统，然后并行初始化用户配置和个人订阅信息，并检查本地AI模型（如Ollama）的运行状态。完成后创建前端状态管理器并渲染主界面，确保用户进入应用即可使用完整功能。",
        "flowchart_mermaid": "graph TD\n    A[启动应用] --> B[加载app_config.toml]\n    B --> C{文件存在?}\n    C -->|否| D[创建默认配置]\n    C -->|是| E[读取配置]\n    D --> F[持久化配置]\n    E --> F\n    F --> G[初始化日志系统]\n    G --> H[加载user_config.toml]\n    H --> I{新用户?}\n    I -->|是| J[生成默认订阅包]\n    I -->|否| K[加载用户数据]\n    J --> L[初始化LLM服务]\n    K --> L\n    L --> M[唤醒Ollama若未运行]\n    M --> N[构建全局状态Store]\n    N --> O[渲染主界面]"
      },
      {
        "name": "订阅内容自动更新流程",
        "description": "系统定时触发订阅源更新任务，对每个订阅项调用对应的抓取器（RSS或搜索引擎），获取最新的文章列表。对于每篇新文章，启动异步处理管道进行内容提取和AI增强处理，并将结果存储至本地数据库，供后续阅读使用。",
        "flowchart_mermaid": "graph TD\n    A[定时触发更新] --> B[遍历所有订阅源]\n    B --> C{类型=RSS?}\n    C -->|是| D[解析RSS XML]\n    C -->|否| E[执行Bing/Baidu搜索]\n    D --> F[提取标题/链接/摘要]\n    E --> F\n    F --> G[抓取文章完整正文]\n    G --> H[检查是否已存在]\n    H -->|否| I[创建新文章记录]\n    H -->|是| J[跳过或标记为新]\n    I --> K[加入LLM处理队列]\n    K --> L[Purge → Optimize → Melt]\n    L --> M[持久化处理结果]\n    M --> N[通知UI刷新列表]"
      },
      {
        "name": "AI助手对话交互流程",
        "description": "用户在AI精灵面板中输入问题后，系统将当前文章内容与用户提问结合，构造提示词发送至LLM代理。代理根据配置选择具体提供商（如Ollama、GLM等）进行推理，并将生成的回答返回前端展示，支持多轮对话历史维护。",
        "flowchart_mermaid": "graph TD\n    A[用户打开AI精灵面板] --> B[输入问题并发送]\n    B --> C[拼接上下文: 文章内容 + 对话历史]\n    C --> D[构造Prompt发送至LLM代理]\n    D --> E{选择LLM提供商}\n    E --> F[调用Ollama/OpenAI/GLM/Mistral]\n    F --> G[接收流式响应]\n    G --> H[前端实时渲染回答]\n    H --> I[追加到对话历史]\n    I --> J[等待下一轮输入]"
      }
    ]
  },
  "timestamp": 1759025329,
  "prompt_hash": "c6c26d9cbe960ea4d90bf7c49a5467f0",
  "token_usage": {
    "input_tokens": 22372,
    "output_tokens": 1387,
    "total_tokens": 23759
  },
  "model_name": null
}